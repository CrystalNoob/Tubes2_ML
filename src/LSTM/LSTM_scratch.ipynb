{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34aee93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from Layers.Embedding import Embedding\n",
    "from Layers.Dense import DenseLayer\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lstm import LSTMScratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5dcd3a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database already separated, so kind\n",
    "train_df = pd.read_csv(\"../../dataset/rnn/train.csv\")\n",
    "val_df = pd.read_csv(\"../../dataset/rnn/valid.csv\")\n",
    "test_df = pd.read_csv(\"../../dataset/rnn/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ccd8220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\"negative\": 0,\n",
    "                 \"neutral\": 1,\n",
    "                 \"positive\": 2\n",
    "                 }\n",
    "\n",
    "# Take text and label only\n",
    "train_df = train_df[[\"text\", \"label\"]]\n",
    "val_df = val_df[[\"text\", \"label\"]]\n",
    "test_df = test_df[[\"text\", \"label\"]]\n",
    "\n",
    "# Warning!!! Not idempotent operations :(\n",
    "train_df[\"label\"] = train_df[\"label\"].map(label_mapping)\n",
    "val_df[\"label\"] = val_df[\"label\"].map(label_mapping)\n",
    "test_df[\"label\"] = test_df[\"label\"].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a014998",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_df[\"text\"].tolist()\n",
    "train_labels = train_df[\"label\"].tolist()\n",
    "\n",
    "val_texts = val_df[\"text\"].tolist()\n",
    "val_labels = val_df[\"label\"].tolist()\n",
    "\n",
    "test_texts = test_df[\"text\"].tolist()\n",
    "test_labels = test_df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99b1879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = keras.layers.TextVectorization(\n",
    "    output_mode='int'\n",
    ")\n",
    "vectorizer.adapt(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4bcd729",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer(np.array(train_texts))\n",
    "x_val = vectorizer(np.array(val_texts))\n",
    "x_test = vectorizer(np.array(test_texts))\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7880b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch Embedder (Layers.Embedding)\n",
    "embedder = Embedding(\n",
    "    input_dim=len(vectorizer.get_vocabulary()), \n",
    "    output_dim=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf4c72b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_embed = embedder(x_train) \n",
    "x_val_embed = embedder(x_val) \n",
    "x_test_embed = embedder(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4895e233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 77, 100)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d75d92c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = self.model.predict(self.X_val)\n",
    "        \n",
    "        # Check if multi-class\n",
    "        if y_pred.ndim > 1 and y_pred.shape[1] > 1:\n",
    "            y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "        else:\n",
    "            y_pred_labels = (y_pred > 0.5).astype(int).flatten()\n",
    "\n",
    "        y_true_labels = self.y_val if len(self.y_val.shape) == 1 else np.argmax(self.y_val, axis=1)\n",
    "        \n",
    "        f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "        print(f'Epoch {epoch + 1} - F1 Score: {f1:.4f}\\n')\n",
    "\n",
    "f1_callback = F1ScoreCallback(x_val_embed, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3b911510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = keras.models.Sequential([\n",
    "#     keras.layers.LSTM(256, return_sequences=True, input_shape=(x_train_embed.shape[1], x_train_embed.shape[2])),\n",
    "#     keras.layers.LSTM(256),\n",
    "    \n",
    "#     keras.layers.Dense(3, activation=\"softmax\")\n",
    "# ])\n",
    "\n",
    "# model1.compile(\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     optimizer=\"adam\",\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# model1.load_weights(\"./training_result/model1.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "102a39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # keras.layers.LSTM(256, return_sequences=True, input_shape=(x_train_embed.shape[1], x_train_embed.shape[2])),\n",
    "#     # keras.layers.LSTM(256),\n",
    "    \n",
    "#     # keras.layers.Dense(3, activation=\"softmax\")\n",
    "\n",
    "\n",
    "# model1_lstm1 = LSTMScratch(256, model1.layers[0].get_weights())\n",
    "# model1_lstm2 = LSTMScratch(256, model1.layers[1].get_weights())\n",
    "# model1_dense = DenseLayer(W=model1.layers[2].get_weights()[0], b=model1.layers[2].get_weights()[1], activation=\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "52aaf768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library_result1 = model1.predict(x_test_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "17d47667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scratch_result1 = model1_lstm1.forward(x_test_embed)\n",
    "# scratch_result1 = model1_lstm2.forward(scratch_result1)\n",
    "# scratch_result1 = model1_dense.forward(scratch_result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "368cb899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scratch_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7bb46e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "02c1e7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SDN 214\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\SDN 214\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "library_model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(32, return_sequences=True, input_shape=(x_train_embed.shape[1], x_train_embed.shape[2])),\n",
    "    keras.layers.LSTM(256, return_sequences=True),\n",
    "    keras.layers.LSTM(64, return_sequences=True),\n",
    "    keras.layers.LSTM(32),\n",
    "    \n",
    "    keras.layers.Dense(3, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "library_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=\"adam\",\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "library_model.load_weights(\"./training_result/model5.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "224308fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_model_lstm1 = LSTMScratch(32, library_model.layers[0].get_weights(), return_sequences=True)\n",
    "scratch_model_lstm2 = LSTMScratch(256, library_model.layers[1].get_weights(), return_sequences=True)\n",
    "scratch_model_lstm3 = LSTMScratch(64, library_model.layers[2].get_weights(), return_sequences=True)\n",
    "scratch_model_lstm4 = LSTMScratch(32, library_model.layers[3].get_weights())\n",
    "scratch_model_dense = DenseLayer(W=library_model.layers[4].get_weights()[0], b=library_model.layers[4].get_weights()[1], activation=\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "76f77c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_scratch(input_features):\n",
    "    result = scratch_model_lstm1.forward(input_features)\n",
    "    result = scratch_model_lstm2.forward(result)\n",
    "    result = scratch_model_lstm3.forward(result)\n",
    "    result = scratch_model_lstm4.forward(result)\n",
    "    result = scratch_model_dense.forward(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "01c4c5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 186ms/step\n"
     ]
    }
   ],
   "source": [
    "library_result = library_model.predict(x_test_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2ee77c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_result = predict_scratch(x_test_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "62cffd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38329223, 0.2144004 , 0.40230736],\n",
       "       [0.38328892, 0.2144478 , 0.40226334],\n",
       "       [0.3832975 , 0.21436313, 0.40233934],\n",
       "       ...,\n",
       "       [0.38318557, 0.2135591 , 0.40325525],\n",
       "       [0.38329357, 0.21441635, 0.40229002],\n",
       "       [0.38330147, 0.2142727 , 0.40242586]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f844c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38329223, 0.21440042, 0.40230735],\n",
       "       [0.38328891, 0.21444775, 0.40226334],\n",
       "       [0.38329748, 0.21436317, 0.40233935],\n",
       "       ...,\n",
       "       [0.38318556, 0.21355915, 0.40325529],\n",
       "       [0.38329359, 0.21441635, 0.40229006],\n",
       "       [0.38330142, 0.21427269, 0.40242588]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scratch_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999ad6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_predicted_class = np.argmax(library_result, axis=1) \n",
    "scratch_predicted_class = np.argmax(scratch_result, axis=1) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
